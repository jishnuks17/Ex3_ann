{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "9jjVGsECiOnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtHd9q8iDg2y"
      },
      "outputs": [],
      "source": [
        "import numpy as np #Importing Numpy for Numerical Operations\n",
        "import pandas as pd #Importing Pandas for Data visualization and Data Analysis\n",
        "import tensorflow as tf #Importing TensorFlow function "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rIcYLcy7EPkJ",
        "outputId": "d3bd0205-6720-4ea3-a82d-f786dc4e7053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv') # Reading dataset from Churn_modelling.csv; Containing 10000 rows and 14 columns \n",
        "x = dataset.iloc[:, 3:-1].values # Assigning 'x' data from churn modelling dataset as inputs; from the dataset all the rows and columns from 3 to 12 \n",
        "y = dataset.iloc[:, -1].values # Last column of dataset is declared as 'y' for output"
      ],
      "metadata": {
        "id": "R0rgQ_XZEcsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:5, :]) # To display first 5 rows from 'x' data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N4pTnP4LYZY",
        "outputId": "ca385a67-b8c3-417e-c97d-dfcb20ddf7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
            " [608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
            " [502 'France' 'Female' 42 8 159660.8 3 1 0 113931.57]\n",
            " [699 'France' 'Female' 39 1 0.0 2 0 0 93826.63]\n",
            " [850 'Spain' 'Female' 43 2 125510.82 1 1 1 79084.1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:1, :]) # To display first row from 'x' data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20o_74bTHc71",
        "outputId": "2b421742-fade-4680-d471-d765dbc660fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y) # Display 'y' data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcucip22Hvbm",
        "outputId": "9a013e79-f29a-4100-e316-77738d4d069f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Categorical data"
      ],
      "metadata": {
        "id": "CYnrDFuFJky_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder # Importing LabelEncoder from sklearn.preprocessing for Encode target labels with value between 0 and n_classes-1\n",
        "le = LabelEncoder() # Declare 'le' variable for LabelEncoder() function\n",
        "x[:, 2] = le.fit_transform(x[:, 2]) # This line encode the column 2 in 'x' data as target values 0 & 1 for gender difference. Male - 1; Female - 0"
      ],
      "metadata": {
        "id": "wRr-eIIVH0VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:5, :]) # To display first 5 rows from 'x' data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40-jLuE3Krtd",
        "outputId": "990facc8-a138-451b-99a9-cee0fed55f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 42 2 0.0 1 1 1 101348.88]\n",
            " [608 'Spain' 0 41 1 83807.86 1 0 1 112542.58]\n",
            " [502 'France' 0 42 8 159660.8 3 1 0 113931.57]\n",
            " [699 'France' 0 39 1 0.0 2 0 0 93826.63]\n",
            " [850 'Spain' 0 43 2 125510.82 1 1 1 79084.1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[4:5, :]) # To display 5th row alone from 'x' data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi1_pBO5Kzm7",
        "outputId": "2fa32377-e028-4a14-c02b-7acc58293860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[850 'Spain' 0 43 2 125510.82 1 1 1 79084.1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column Transformer Function\n",
        "sciket-learn class used to create and apply separate transformers for numerical and categorical data."
      ],
      "metadata": {
        "id": "ntjUk4SiupmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer # Importing ColumnTransformer function from sklearn library\n",
        "from sklearn.preprocessing import OneHotEncoder #Import OneHotEncoder function for preprocessing from sklearn\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder = 'passthrough') # Transformer Name: encoder; OneHotEncoder constructor for 2nd column datas are transformed into estimator; Remainder:Without any changes pass the values.  \n",
        "X = np.array(ct.fit_transform(x)) # To fit and transform the dataset to label encode and one hot encode the column"
      ],
      "metadata": {
        "id": "Sh5TTr3cLMox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[:1,:]) # Display 1st row data after ColumnTransformer function done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70IaIj1ZNaVU",
        "outputId": "89fb87e0-6fe7-418f-9ba6-c81670f878f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation and Preprocessing"
      ],
      "metadata": {
        "id": "Aq7TNu9Cg5fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # # This function splitting the data as train and test with the help of sklearn.model_selection\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0) ## Train_set = 80%; Test_set = 20%; Random_sample = 0"
      ],
      "metadata": {
        "id": "TVQLxiFgNzHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler #importing StandardScaler function from sklearn.preprocessing directory\n",
        "sc = StandardScaler() # Declare variable 'sc' for the output of StandardScaler function\n",
        "X_train = sc.fit_transform(x_train) # x_train standardscaler transformation has done and save the output in X_train variable\n",
        "X_test = sc.transform(x_test) # x_test standardscaler transformation has done and save the output in X_test variable"
      ],
      "metadata": {
        "id": "IwGDkFL5OQ0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Preparation and Evaluation"
      ],
      "metadata": {
        "id": "ZYd0Izw7kCT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()  # A sequential model to pass various ANN layers\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) # ANN Layer1 with 6 neurons/ hidden layers and activation function used here is \"ReLu\" Rectified Linear Unit\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) # ANN Layer2 with 6 neurons/ hidden layers and activation function used here is \"ReLu\"\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Output layer with activation function as 'Sigmoid' for binary classification"
      ],
      "metadata": {
        "id": "MntV-ivhRl4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile model"
      ],
      "metadata": {
        "id": "bHKLNE4Xp9_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam',loss= 'binary_crossentropy', metrics = ['accuracy']) # Compiling done with the 'adam'(Adaptable Optimizer); Loss = binary_crossentropy for binary classification and metrics measured in this is accuracy"
      ],
      "metadata": {
        "id": "iT-wOzYtUfRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100) # Evaluation metrics for training accuracy determination with batch_size of 32 and No. of epochs = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpU2rGaCXVqa",
        "outputId": "13de6384-5dd3-4792-bd7b-e98e448984e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 2s 2ms/step - loss: 0.5071 - accuracy: 0.7960\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7956\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7940\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7951\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7966\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7980\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8099\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8152\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8260\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8307\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8397\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8479\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8544\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8568\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8576\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8584\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8606\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8608\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8616\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8610\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8612\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8615\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8627\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8625\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8608\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8619\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8626\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8624\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8621\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8605\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8621\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8629\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8629\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8622\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8636\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8636\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8640\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8644\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8634\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8634\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8649\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8630\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8631\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8636\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8641\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8640\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8636\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8640\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8646\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8640\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8639\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8637\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8648\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8639\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8633\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8629\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8633\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8621\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8654\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8646\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8637\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8659\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8645\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8648\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8644\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8631\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8634\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8633\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8649\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8635\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8652\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8655\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8659\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8650\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8645\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8655\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8654\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8644\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8639\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8639\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8643\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8649\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8640\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8652\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8648\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8651\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8644\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8651\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8656\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8646\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8655\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8661\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8648\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8652\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8644\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8654\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8658\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8651\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8645\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d73d71050>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 60) # Evaluation metrics for training accuracy determination with batch_size of 32 and No. of epochs = 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM9cjY3IXblp",
        "outputId": "2ed78a7f-5639-404f-e6e6-ff6e227a48e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8660\n",
            "Epoch 2/60\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8655\n",
            "Epoch 3/60\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8660\n",
            "Epoch 4/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8656\n",
            "Epoch 5/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8656\n",
            "Epoch 6/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8668\n",
            "Epoch 7/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8661\n",
            "Epoch 8/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8656\n",
            "Epoch 9/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8652\n",
            "Epoch 10/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8648\n",
            "Epoch 11/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8666\n",
            "Epoch 12/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8640\n",
            "Epoch 13/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8644\n",
            "Epoch 14/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8656\n",
            "Epoch 15/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8650\n",
            "Epoch 16/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8645\n",
            "Epoch 17/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8652\n",
            "Epoch 18/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8655\n",
            "Epoch 19/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8659\n",
            "Epoch 20/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8641\n",
            "Epoch 21/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8666\n",
            "Epoch 22/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8662\n",
            "Epoch 23/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8658\n",
            "Epoch 24/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8651\n",
            "Epoch 25/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8660\n",
            "Epoch 26/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8651\n",
            "Epoch 27/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8658\n",
            "Epoch 28/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8668\n",
            "Epoch 29/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8648\n",
            "Epoch 30/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8656\n",
            "Epoch 31/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8661\n",
            "Epoch 32/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8656\n",
            "Epoch 33/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8661\n",
            "Epoch 34/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8670\n",
            "Epoch 35/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8664\n",
            "Epoch 36/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8661\n",
            "Epoch 37/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8651\n",
            "Epoch 38/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8643\n",
            "Epoch 39/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8659\n",
            "Epoch 40/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8660\n",
            "Epoch 41/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8666\n",
            "Epoch 42/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8651\n",
            "Epoch 43/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8664\n",
            "Epoch 44/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 45/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8662\n",
            "Epoch 46/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 47/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8661\n",
            "Epoch 48/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8656\n",
            "Epoch 49/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8661\n",
            "Epoch 50/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 51/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8666\n",
            "Epoch 52/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8658\n",
            "Epoch 53/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8659\n",
            "Epoch 54/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8668\n",
            "Epoch 55/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8676\n",
            "Epoch 56/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8660\n",
            "Epoch 57/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8659\n",
            "Epoch 58/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 59/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8675\n",
            "Epoch 60/60\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8665\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d73e0af50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.summary() # Display summary of model architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Vv8tPiZIYP",
        "outputId": "a80ca160-4811-4a76-dec5-cc353ee0c015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (32, 6)                   78        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (32, 6)                   42        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (32, 1)                   7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127\n",
            "Trainable params: 127\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))>0.5) # ANN prediction result as if \"output>0.5\" print 'False' else 'True' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Z6mJBuZWBK",
        "outputId": "6e3e3ca5-2388-4903-82c8-3b69674142ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test) # ANN Prediction for x_test for test data \n",
        "y_pred = (y_pred > 0.5) # Fixing threshold condition as 0.5 to predict the result.\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)) # Concatenating the y_pred and y_test through reshape and printing the result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hPVsPewbW0W",
        "outputId": "9389eda4-0699-4041-c331-555cb0b5bc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score # Importing accuracy_score and confusion_matrix from sklearn.metrics\n",
        "cm = confusion_matrix(y_test, y_pred), # Fetching y_test and y_pred data to determine confusion matrix\n",
        "print(cm) # Display Confusion matrix result\n",
        "accuracy_score(y_test, y_pred) # Evaluation of final accuracy score of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smcxMbswb61H",
        "outputId": "4d8ece44-96fe-40f1-c7b2-a26784b7bdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1495,  100],\n",
            "       [ 187,  218]]),)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8565"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OoBO9_mKdyEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}